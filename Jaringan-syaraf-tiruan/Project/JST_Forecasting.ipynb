{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94ba56b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_tuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras_tuner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkt\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraphics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtsaplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_acf\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'keras_tuner'"
     ]
    }
   ],
   "source": [
    "# 1. IMPORT LIBRARY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b092e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Parameter utama\n",
    "FILE_PATH = \"dataset_bbri.xlsx\"\n",
    "SHEET_NAME = 'Sheet1'\n",
    "TARGET_COLUMN = 'Close'\n",
    "LOOK_BACK = 7\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "TUNER_MAX_TRIALS = 10\n",
    "TUNER_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b806449",
   "metadata": {},
   "source": [
    "# Persiapan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff75b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_mlp(dataset, look_back=1):\n",
    "    \"\"\"\n",
    "    Mengubah array nilai menjadi format dataset untuk MLP.\n",
    "    Contoh:\n",
    "    dataset = [1, 2, 3, 4, 5]\n",
    "    look_back = 2\n",
    "    Maka hasilnya:\n",
    "    dataX = [[1, 2], [2, 3], [3, 4]]\n",
    "    dataY = [3, 4, 5]\n",
    "    \"\"\"\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        # Ambil sequence [i] s/d [i+look_back] sebagai fitur\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        dataX.append(a)\n",
    "        # Ambil data [i + look_back] sebagai target\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ea5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat data dari dataset_bbri.xlsx (Fitur: Close)...\n",
      "Error: Library 'openpyxl' tidak ditemukan.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Library \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m tidak ditemukan.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m     exit()\n\u001b[1;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData berhasil dimuat.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Ambil nilai 'Close' dan ubah menjadi numpy array\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "print(f\"Memuat data dari {FILE_PATH} (Fitur: {TARGET_COLUMN})...\")\n",
    "df = pd.read_excel(\n",
    "    FILE_PATH,\n",
    "    sheet_name=SHEET_NAME,\n",
    "    usecols=['Date', TARGET_COLUMN],\n",
    "    parse_dates=['Date'],\n",
    "    index_col='Date',\n",
    "    engine='openpyxl'\n",
    ")\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"\\nPreview Data:\")\n",
    "display(df.head())\n",
    "\n",
    "dataset_values = df[TARGET_COLUMN].values.reshape(-1, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853b01b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7baaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset sebelum scaling\n",
    "train_size = int(len(dataset_values) * TRAIN_SPLIT_RATIO)\n",
    "train_values = dataset_values[:train_size]\n",
    "test_values  = dataset_values[train_size:]\n",
    "\n",
    "# Fit scaler hanya pada data training\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(train_values)\n",
    "scaled_train = scaler.transform(train_values)\n",
    "scaled_test  = scaler.transform(test_values)\n",
    "\n",
    "# Buat dataset MLP\n",
    "X_train, y_train = create_dataset_mlp(scaled_train, LOOK_BACK)\n",
    "X_test, y_test   = create_dataset_mlp(scaled_test, LOOK_BACK)\n",
    "\n",
    "print(f\"Shape X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Shape X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. PISAHKAN DATA TRAINING DAN TESTING\n",
    "train_size = int(len(scaled_dataset) * TRAIN_SPLIT_RATIO)\n",
    "test_size = len(scaled_dataset) - train_size\n",
    "\n",
    "train_data = scaled_dataset[0:train_size, :]\n",
    "test_data = scaled_dataset[train_size:len(scaled_dataset), :]\n",
    "\n",
    "print(f\"Ukuran data training: {len(train_data)}\")\n",
    "print(f\"Ukuran data testing: {len(test_data)}\")\n",
    "\n",
    "# Buat dataset X dan y\n",
    "X_train, y_train = create_dataset_mlp(train_data, LOOK_BACK)\n",
    "X_test, y_test = create_dataset_mlp(test_data, LOOK_BACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. BENTUK ULANG (RESHAPE) DATA\n",
    "# Untuk MLP, kita tidak memerlukan reshape 3D.\n",
    "# Input X sudah benar: (samples, features_in) -> (samples, LOOK_BACK)\n",
    "print(f\"Shape X_train (untuk MLP): {X_train.shape}\")\n",
    "print(f\"Shape X_test (untuk MLP): {X_test.shape}\")\n",
    "print(f\"Shape y_train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. BANGUN MODEL MLP (MULTILAYER PERCEPTRON)\n",
    "print(\"Membangun model MLP...\")\n",
    "\n",
    "model = Sequential()\n",
    "# Input layer (Dense) dengan input_dim = LOOK_BACK\n",
    "model.add(Dense(units=100, input_dim=LOOK_BACK, activation='relu'))\n",
    "# Hidden layer\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "# Output layer (1 neuron, tanpa aktivasi / linear)\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Kompilasi model. 'adam' adalah optimizer yang menerapkan backpropagation\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. LATIH MODEL\n",
    "print(f\"Mulai training model MLP (Epochs={EPOCHS}, Batch Size={BATCH_SIZE})...\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Training selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51237ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. LAKUKAN PREDIKSI\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. KEMBALIKAN DATA KE SKALA SEMULA (INVERSE TRANSFORM)\n",
    "# (Kembali ke cara inverse univariate yang sederhana)\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train_orig = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test_orig = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. HITUNG ROOT MEAN SQUARED ERROR (RMSE)\n",
    "train_rmse = math.sqrt(mean_squared_error(y_train_orig, train_predict))\n",
    "test_rmse = math.sqrt(mean_squared_error(y_test_orig, test_predict))\n",
    "\n",
    "print(f\"\\n--- HASIL EVALUASI (MODEL MLP) ---\")\n",
    "print(f\"Train RMSE: {train_rmse:.2f}\")\n",
    "print(f\"Test RMSE:  {test_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4dde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung MAE\n",
    "train_mae = mean_absolute_error(y_train_orig, train_predict)\n",
    "test_mae = mean_absolute_error(y_test_orig, test_predict)\n",
    "\n",
    "# Hitung MAPE (gunakan numpy.mean untuk menghindari error pembagian nol)\n",
    "# Tambahkan epsilon kecil untuk menghindari pembagian dengan nol\n",
    "epsilon = 1e-10\n",
    "train_mape = np.mean(np.abs((y_train_orig - train_predict) / (y_train_orig + epsilon))) * 100\n",
    "test_mape = np.mean(np.abs((y_test_orig - test_predict) / (y_test_orig + epsilon))) * 100\n",
    "\n",
    "\n",
    "print(f\"\\n--- HASIL EVALUASI ---\")\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE:  {test_mae:.2f}\")\n",
    "print(f\"Train MAPE: {train_mape:.2f}%\")\n",
    "print(f\"Test MAPE:  {test_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98708b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. VISUALISASIKAN HASIL PREDIKSI\n",
    "print(\"Membuat plot hasil prediksi...\")\n",
    "\n",
    "# Siapkan data untuk plot\n",
    "# Buat array kosong seukuran data asli, isi dengan NaN\n",
    "train_predict_plot = np.empty_like(scaled_dataset)\n",
    "train_predict_plot[:, :] = np.nan\n",
    "# Isi bagian data training dengan hasil prediksi\n",
    "train_predict_plot[LOOK_BACK:len(train_predict) + LOOK_BACK, :] = train_predict\n",
    "\n",
    "# Lakukan hal yang sama untuk data testing\n",
    "test_predict_plot = np.empty_like(scaled_dataset)\n",
    "test_predict_plot[:, :] = np.nan\n",
    "test_plot_start_index = train_size + LOOK_BACK\n",
    "test_predict_plot[test_plot_start_index : test_plot_start_index + len(test_predict), :] = test_predict\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "# Plot data asli\n",
    "plt.plot(df.index, scaler.inverse_transform(scaled_dataset), label='Data Asli (Close)')\n",
    "# Plot prediksi training\n",
    "plt.plot(df.index, train_predict_plot, label='Prediksi Training')\n",
    "# Plot prediksi testing\n",
    "plt.plot(df.index, test_predict_plot, label='Prediksi Testing')\n",
    "\n",
    "plt.title(f'Prediksi Harga Saham (MLP) - Test RMSE: {test_rmse:.2f}')\n",
    "plt.xlabel('Tanggal')\n",
    "plt.ylabel('Harga Close')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ae62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. VISUALISASIKAN LOSS TRAINING VS VALIDASI\n",
    "print(\"Membuat plot loss model...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Training & Validation Loss (Model MLP)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residuals = y_train_orig.flatten() - train_predict.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Membuat plot autokorelasi residu training...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_acf(train_residuals, alpha=0.05)\n",
    "plt.title('Autokorelasi Residu (ACF) - Model MLP')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autokorelasi')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ff51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_residuals = y_test_orig.flatten() - test_predict.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Membuat plot autokorelasi residu testing...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_acf(test_residuals, alpha=0.05)\n",
    "plt.title('Autokorelasi Residu (ACF) - Model MLP')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autokorelasi')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
